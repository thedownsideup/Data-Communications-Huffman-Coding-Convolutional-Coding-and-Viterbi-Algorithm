{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Communications : Huffman Coding, Convolutional Coding and Viterbi Algorithm\n",
    "Mahsa Eskandari Ghadi         \n",
    "Student No. 810196597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we look at encoding algorithms such as Huffman and Convolutional coding and decoding algorithms such as Viterbi algorithm.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import heapq\n",
    "import string\n",
    "import numpy as np\n",
    "import operator\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='AEB6BF'><b>Source Coding : Huffman Coding</b></font>\n",
    "In Huffman Coding each alphabetic letter has a frequency which helps us determine the codeword for it, that which results in \"the bigger the frequency the smaller the codeword\" in this way we can have a smaller data in the end than having the same size for all or randomly assigning codewords.\n",
    "\n",
    "<img src=\"HuffmanHeap.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alphabet is: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "alphabet = list(string.ascii_lowercase)\n",
    "print(\"The alphabet is:\", alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: \n",
      " [[0.08167]\n",
      " [0.01492]\n",
      " [0.02782]\n",
      " [0.04253]\n",
      " [0.12702]\n",
      " [0.02228]\n",
      " [0.02015]\n",
      " [0.06094]\n",
      " [0.06966]\n",
      " [0.00153]\n",
      " [0.00772]\n",
      " [0.04025]\n",
      " [0.02406]\n",
      " [0.06749]\n",
      " [0.07507]\n",
      " [0.01929]\n",
      " [0.00095]\n",
      " [0.05987]\n",
      " [0.06327]\n",
      " [0.09056]\n",
      " [0.02758]\n",
      " [0.00978]\n",
      " [0.0236 ]\n",
      " [0.0015 ]\n",
      " [0.01947]\n",
      " [0.00102]]\n"
     ]
    }
   ],
   "source": [
    "table = loadmat('freq.mat')\n",
    "frequencies = table['freq']\n",
    "print(\"Frequencies: \\n\", frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained before the value of frequency makes a difference in choosing the codewords; this indicates <b>sorting</b>.<br> a <b>Heap</b> is a maximally efficient implementation of an abstract data type called a priority queue. Heap basically <b>sorts itself</b> no matter when or where you want to insert a or remove an item from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a HeapNode as shown below: for each alphabetic letter we have a node that has it's own frequency and as the Huffman code algorithm needs us to, we define 2 childs for each node; a left and a right. We want the heap to sort these nodes depending on their frequencies therefore a \"greater than\" function is defined to sort in that manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeapNode:\n",
    "   \n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.freq > other.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a Huffman Encoder is an object that has methods that can encode given an alphabetic string and decode given a numerical binary string via other methods which will be explained.<br>\n",
    "\n",
    "- make_dict simply makes a dictionary that uses letters as keys and frequencies as values.\n",
    "- make_heap makes a heap depending on the frequencies assigned to each letter in the previous method.\n",
    "- merge_nodes merges the 2 smallest frequencies and pushes the new node to the heap\n",
    "- recursive_make_codes assigns 0 to the left edge and 1 to the right edge and does this recursively for all nodes.\n",
    "- make_codes pops the root from the heap and calls recursive_make_codes for the first time.\n",
    "<br>\n",
    "the encode method calls the above methods and is trivial. <br>\n",
    "Huffman Encoder as an additional attribute <b>\"reverse_mapping\"</b> which is the opposite dictionary to encoding meaning the keys are the codewords and the values are the alphabetic letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanEncoder:\n",
    "    \n",
    "    def __init__(self, input_text, frequencies):\n",
    "        self.input_text = input_text\n",
    "        self.frequencies = frequencies\n",
    "        self.heap = []\n",
    "        self.codes = {}\n",
    "        self.reverse_mapping = {}\n",
    "        \n",
    "    def make_dict(self):\n",
    "        return {k:v for k,v in zip(alphabet, frequencies)}\n",
    "        \n",
    "    def make_heap(self, freq_dict):\n",
    "        for key in alphabet:\n",
    "            node = HeapNode(key, freq_dict[key])\n",
    "            heapq.heappush(self.heap, node)\n",
    "            \n",
    "    def merge_nodes(self):\n",
    "        while(len(self.heap) > 1):\n",
    "            node1 = heapq.heappop(self.heap)\n",
    "            node2 = heapq.heappop(self.heap)\n",
    "\n",
    "            merged = HeapNode(None, node1.freq + node2.freq)\n",
    "            merged.left = node1\n",
    "            merged.right = node2\n",
    "\n",
    "            heapq.heappush(self.heap, merged)\n",
    "            \n",
    "    \n",
    "    def recursive_make_codes(self, root, current_code):\n",
    "        if(root == None):\n",
    "            return\n",
    "\n",
    "        if(root.char != None):\n",
    "            self.codes[root.char] = current_code\n",
    "            self.reverse_mapping[current_code] = root.char\n",
    "            return\n",
    "\n",
    "        self.recursive_make_codes(root.left, current_code + \"0\")\n",
    "        self.recursive_make_codes(root.right, current_code + \"1\")\n",
    "\n",
    "\n",
    "    def make_codes(self):\n",
    "        root = heapq.heappop(self.heap)\n",
    "        current_code = \"\"\n",
    "        self.recursive_make_codes(root, current_code)\n",
    "        \n",
    "    def get_encoded(self, text):\n",
    "        encoded_text = \"\"\n",
    "        for character in text:\n",
    "            encoded_text += self.codes[character]\n",
    "        return encoded_text\n",
    "    \n",
    "    def encode(self):\n",
    "        freq_dict = self.make_dict()\n",
    "        self.make_heap(freq_dict)\n",
    "        self.merge_nodes()\n",
    "        self.make_codes()\n",
    "        self.encoded_text = self.get_encoded(self.input_text)\n",
    "        return self.encoded_text\n",
    "        \n",
    "    def decode(self):\n",
    "        current_code = \"\"\n",
    "        decoded_text = \"\"\n",
    "\n",
    "        for bit in self.encoded_text:\n",
    "            current_code += bit\n",
    "            if(current_code in self.reverse_mapping):\n",
    "                character = self.reverse_mapping[current_code]\n",
    "                decoded_text += character\n",
    "                current_code = \"\"\n",
    "                \n",
    "        return decoded_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bhrigu.me/blog/2017/01/17/huffman-coding-python-implementation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001111110011001111110100011100101111110101011111111001011011'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huffman_encoder = HuffmanEncoder(\"mahsaeskandari\", frequencies)\n",
    "huffman_encoder.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mahsaeskandari'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huffman_encoder.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#AEB6BF'><b>Channel Coding : Convolutional Coding</b></font>\n",
    "Convolutional encoder on the other hand uses a state machine to encode a binary string. Figure Below: <br>\n",
    "![title](StateMachine.png) <br>\n",
    "To implement this state machine we view each state as a function where depending on the state (function) different actions are taken and to move from one state to another the current function simply calls another function. the starting state is called by the encode method to start off the state machine. Each time a state function is called a bit is read from the input bits and removed from the original then an action is taken depending on that bit and the next state is called. Once the string is empty the function at that moment returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalEncoder:\n",
    "\n",
    "    def __init__(self, input_bits):\n",
    "        self.input_bits = list(input_bits)\n",
    "        self.encoded = []\n",
    "        \n",
    "    def zerozero(self):\n",
    "        if len(self.input_bits) == 0:\n",
    "            return\n",
    "            \n",
    "        bit = self.input_bits.pop(0)\n",
    "        if bit == '0':\n",
    "            self.encoded.append('00')\n",
    "            self.zerozero()\n",
    "        else:\n",
    "            self.encoded.append('11')\n",
    "            self.onezero()\n",
    "            \n",
    "    def onezero(self):\n",
    "        if len(self.input_bits) == 0:\n",
    "            return\n",
    "        bit = self.input_bits.pop(0)\n",
    "        \n",
    "        if bit == '0':\n",
    "            self.encoded.append('11')\n",
    "            self.zeroone()\n",
    "        else:\n",
    "            self.encoded.append('00') \n",
    "            self.oneone()\n",
    "            \n",
    "            \n",
    "    def oneone(self):\n",
    "        if len(self.input_bits) == 0:\n",
    "            return\n",
    "            \n",
    "        bit = self.input_bits.pop(0)\n",
    "        if bit == '0':\n",
    "            self.encoded.append('01')\n",
    "            self.zeroone()\n",
    "        else:\n",
    "            self.encoded.append('10')\n",
    "            self.oneone()\n",
    "            \n",
    "    def zeroone(self):\n",
    "        if len(self.input_bits) == 0:\n",
    "            return\n",
    "            \n",
    "        bit = self.input_bits.pop(0)\n",
    "        if bit == '0':\n",
    "            self.encoded.append('10')\n",
    "            self.zerozero()\n",
    "        else:\n",
    "            self.encoded.append('01')\n",
    "            self.onezero()\n",
    "\n",
    "    def encode(self):\n",
    "        self.zerozero()\n",
    "        return ''.join(self.encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'111110110010'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutional_encoder = ConvolutionalEncoder('100111')\n",
    "convolutional_encoder.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#AEB6BF'><b>Viterbi Algorithm</b></font>\n",
    "To implement the Viterbi Algorithm we need a Trellis diagram. Each Trellis node has 2 paths for each <b>parent</b>. Considering we're in a <b>to_state</b> we will need the <b>from_state</b> for it's <b>path metric</b> and the weight of the edge for <b>branch metric</b> to determine which way is the most likely way that has been taken when encoding so that we can trace that back and decode the encoded thing:D <br>\n",
    "![title](TrellisDiagram.png) <br>\n",
    "\n",
    "So by path1 and path2 I mean a list of, the code on the edge (the 11 in 0/11), the <b>Hamming Distance</b> of the code on the edge and the received bits (or the branch metric), the number of the from_state, the decoded bit (the 0 in 0/11) respectively for each from_state. And that's all we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrellisNode:\n",
    "   \n",
    "    def __init__(self, path1, path2):\n",
    "        self.path1 = path1\n",
    "        self.path2 = path2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're holding 4 nodes at a time since Viterbi is a <b>Dynamic Programming</b> algorithm; We only need the current nodes to find the next ones.\n",
    "- hamming is a method that given two lists of bits determines the hamming distance of a the lists for example for [1,0] and [0,1] the hamming distance is '2'. It will come in handy later.\n",
    "- calculate_branch_metrics takes the first two bits of the received data then removes those two bits from the original received data so that once it's empty the decoding is over. After this it calculates the hamming distance between them and saves that to the paths explained before (again for each path of each node)\n",
    "- When branch metrics are known we can move on to calculating the path metrics via the calculate_path_metrics method; which calculates the path metrics of the new nodes according to the equation below: <br>\n",
    "<br>\n",
    "$PM[s, i+1] = min(PM[a, i] + BM[a\\rightarrow s], PM[b, i] + BM[b\\rightarrow s])$ <br>\n",
    "<br>\n",
    "Everytime we reach a new PM list the min of that is declared to be the most likely state and the path is saved.\n",
    "\n",
    "- the decode method simply calls the above methods in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViterbiDecoder:\n",
    "\n",
    "    def __init__(self, encoded):\n",
    "        self.encoded = encoded\n",
    "        #[code, hd, from_state, decoded]\n",
    "        self.nodes = [TrellisNode(['00', 0, 0, 0], ['10', 0, 1, 0]), TrellisNode(['11', 0, 2, 0], ['01', 0, 3, 0]), TrellisNode(['11', 0, 0, 1], ['01', 0, 1, 1]), TrellisNode(['00', 0, 2, 1], ['10', 0, 3, 1])]\n",
    "        self.PMs = [0, 0, 0, 0]\n",
    "        self.path = []\n",
    "        self.res_path = []\n",
    "        \n",
    "        # compute hamming distance of two bit sequences\n",
    "    def hamming(self, s1, s2):\n",
    "        return sum(map(operator.xor,s1,s2)) #cool right?\n",
    "    \n",
    "    def calculate_branch_metrics(self):\n",
    "        \n",
    "        encoded_bits = list(self.encoded[:2])\n",
    "        self.encoded = self.encoded[2:]\n",
    "        \n",
    "        for i, bit in enumerate(encoded_bits):\n",
    "            encoded_bits[i] = int(bit)\n",
    "            \n",
    "        for node in self.nodes:\n",
    "            edgebits = list(node.path1[0])\n",
    "            \n",
    "            for i, bit in enumerate(edgebits):\n",
    "                edgebits[i] = int(bit)\n",
    "            \n",
    "            node.path1[1] = self.hamming(encoded_bits, edgebits)\n",
    "\n",
    "            edgebits = list(node.path2[0])\n",
    "            for i, bit in enumerate(edgebits):\n",
    "                edgebits[i] = int(bit)\n",
    "            \n",
    "            node.path2[1] = self.hamming(encoded_bits, edgebits)\n",
    "            \n",
    "    def calculate_path_metrics(self):\n",
    "        #[code, hd, from_state, decoded]\n",
    "        newPMs = [0, 0, 0, 0]\n",
    "        for i, node in enumerate(self.nodes):\n",
    "            values = [self.PMs[node.path1[2]] + node.path1[1], self.PMs[node.path2[2]] + node.path2[1]]\n",
    "\n",
    "            newPMs[i] = min(values)\n",
    "            if values.index(min(values)) == 0:\n",
    "                self.path.append(node.path1[3])\n",
    "            else:\n",
    "                self.path.append(node.path2[3])\n",
    "        self.PMs = newPMs\n",
    "\n",
    "    def viterbi_step(self):\n",
    "        \n",
    "        most_likely_state = min(self.PMs)\n",
    "        self.res_path.append(self.path[self.PMs.index(most_likely_state)])\n",
    "\n",
    "    def decode(self):\n",
    "        \n",
    "        while self.encoded:\n",
    "            self.calculate_branch_metrics()\n",
    "            self.calculate_path_metrics()\n",
    "            self.viterbi_step()\n",
    "            \n",
    "        for i, path in enumerate(self.res_path):\n",
    "            self.res_path[i] = str(path)\n",
    "        return ''.join(self.res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000111'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_decoder = ViterbiDecoder('111110110010')\n",
    "viterbi_decoder.decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To capture reality better it is likely for a noise to influence the output of channel encoding. Putting it all together we have the results shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'001001000011001001000100001001001000000001011100111001011011'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huffman_encoder = HuffmanEncoder(\"mahsaeskandari\", frequencies)\n",
    "source_encoded = huffman_encoder.encode()\n",
    "\n",
    "convolutional_encoder = ConvolutionalEncoder(source_encoded)\n",
    "channel_encoded = convolutional_encoder.encode()\n",
    "channel_encoded = list(channel_encoded)\n",
    "\n",
    "for i, bit in enumerate(channel_encoded):\n",
    "    channel_encoded[i] = int(bit)\n",
    "    \n",
    "noised = noise.noise(channel_encoded)\n",
    "\n",
    "for i, bit in enumerate(noised):\n",
    "    noised[i] = str(bit)\n",
    "    \n",
    "noised = ''.join(noised)\n",
    "\n",
    "viterbi_decoder = ViterbiDecoder(noised)\n",
    "viterbi_decoder.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda85cb869ba3f54f519968a1db97ce143c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
